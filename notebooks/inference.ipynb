{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model, Model  \n",
    "from loss import custom_loss_wrapper\n",
    "import os \n",
    "import h5py\n",
    "import glob\n",
    "from utils import convertXY2PtPhi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c38afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/home/users/dprimosc/L1METML/experiments/l1metml_v1/25May21_normf100_clip_140X/'\n",
    "model_name = '25May21_normf100_clip_140Xmodel.h5'\n",
    "model = load_model(model_dir + model_name, custom_objects={'custom_loss':custom_loss_wrapper})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing done in .h5 conversion\n",
    "sample = 'VBFHToBB'\n",
    "tag = '25Jul8_140X_v0'\n",
    "data_dir = f'/ceph/cms/store/user/dprimosc/l1deepmet_data/{tag}/{sample}_PU200/FP/140Xv0/'\n",
    "#data_dir = f'/ceph/cms/store/user/dprimosc/l1deepmet_data/{tag}/'\n",
    "h5_files = glob.glob(os.path.join(data_dir, f'*.h5'))\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa676e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate data from all files\n",
    "X_data_list = []\n",
    "Y_data_list = []\n",
    "\n",
    "for h5_file in h5_files:\n",
    "    print(f\"Loading {os.path.basename(h5_file)}...\")\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        # Check what datasets are available\n",
    "        if len(X_data_list) == 0:  # Only print once\n",
    "            print(\"Datasets in file:\", list(f.keys()))\n",
    "        \n",
    "        # Load X and Y data\n",
    "        X_batch = f['X'][:]  # Shape: (n_events, n_particles, n_features)\n",
    "        Y_batch = f['Y'][:]  # Shape: (n_events, 2)\n",
    "        \n",
    "        X_data_list.append(X_batch)\n",
    "        Y_data_list.append(Y_batch)\n",
    "        print(f\"  Loaded {X_batch.shape[0]} events\")\n",
    "\n",
    "# Concatenate all data\n",
    "data = np.concatenate(X_data_list, axis=0)  # Shape: (total_events, n_particles, n_features)\n",
    "Y = np.concatenate(Y_data_list, axis=0)     # Shape: (total_events, 2)\n",
    "\n",
    "print(f\"\\nTotal concatenated data shape: {data.shape}\")\n",
    "print(f\"Total target shape: {Y.shape}\")\n",
    "print(f\"Total events: {data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is loaded and has shape (batch_size, 128, >=8)\n",
    "# Reconstruct X0-X3 from the 'data' array according to the encoding\n",
    "\n",
    "# X0: pt, eta, phi, puppiW\n",
    "X0 = data[:, :, [0, 3, 4, 5]]\n",
    "\n",
    "# X1: px, py\n",
    "X1 = data[:, :, [1, 2]]\n",
    "\n",
    "# X2: encoded pdgId\n",
    "X2 = data[:, :, 6].astype(int)\n",
    "\n",
    "# X3: encoded charge\n",
    "X3 = data[:, :, 7].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae67fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure X2 and X3 indices are within the valid range for the embedding layer\n",
    "#X2_clipped = np.clip(X2, 0, 3)\n",
    "#X3_clipped = np.clip(X3, 0, 3)\n",
    "\n",
    "# Run inference\n",
    "prediction = model.predict([X0, X1, X2, X3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2715b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the magnitude (Euclidean norm) of each prediction vector\n",
    "#prediction_magnitudes = np.linalg.norm(predictions, axis=1)\n",
    "prediction_PtPhi = convertXY2PtPhi(prediction)\n",
    "#target_magnitudes = np.linalg.norm(Y, axis=1)\n",
    "target_PtPhi = convertXY2PtPhi(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb522cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions as the feature array\n",
    "np.save(os.path.join(model_dir, f\"{sample}_feature_array_MLMET.npy\"), prediction)\n",
    "\n",
    "# Save the target array Y \n",
    "np.save(os.path.join(model_dir, f\"{sample}_target_array_MLMET.npy\"), Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd10140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: check for correctness\n",
    "# Compute PUPPI MET prediction using input features\n",
    "# px = pt * cos(phi), py = pt * sin(phi), puppiw = X1[..., 1]\n",
    "# X0[..., 1] = pt*cos(phi), X0[..., 2] = pt*sin(phi), X1[..., 1] = puppiw\n",
    "\n",
    "# Sum over all particles for each event: MET_px = -sum(puppiw * px), MET_py = -sum(puppiw * py)\n",
    "puppi_px = X1[..., 0] * X0[..., 3]\n",
    "puppi_py = X1[..., 1] * X0[..., 3]\n",
    "puppi_met_components = np.stack([\n",
    "    -np.sum(puppi_px, axis=1),\n",
    "    -np.sum(puppi_py, axis=1)\n",
    "], axis=1)\n",
    "\n",
    "# Calculate MET magnitude from px, py components\n",
    "#puppi_met_magnitude = np.linalg.norm(puppi_met_components, axis=1)  # Shape: (n_events,)\n",
    "puppi_met_PtPhi = convertXY2PtPhi(puppi_met_components)\n",
    "\n",
    "# Calculate target MET magnitude\n",
    "#target_met_magnitude = np.linalg.norm(Y, axis=1)  # Shape: (n_events,)\n",
    "\n",
    "# Save PUPPI MET predictions as the feature array\n",
    "np.save(os.path.join(model_dir, f\"{sample}_feature_array_PUMET.npy\"), puppi_met_components)\n",
    "\n",
    "# Save the target array for PUPPI MET\n",
    "np.save(os.path.join(model_dir, f\"{sample}_target_array_PUMET.npy\"), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(puppi_met_components.shape)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e082cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of events in TTbar and SingleNeutrino datasets\n",
    "#ttbar_events = Tarray_PU.shape[0]\n",
    "#singleneutrino_events = predictions.shape[0]\n",
    "\n",
    "#print(f\"Number of TTbar events: {ttbar_events}\")\n",
    "#print(f\"Number of SingleNeutrino events: {singleneutrino_events}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0160f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histogram for predictions (MLMET feature array)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(prediction[:, 0], bins=50, alpha=0.7, label='MLMET px')\n",
    "plt.hist(prediction[:, 1], bins=50, alpha=0.7, label='MLMET py')\n",
    "plt.title('MLMET Predictions')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "# Plot histogram for Y (MLMET target array)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(Y[:, 0], bins=500, alpha=0.7, label='Target px')\n",
    "plt.hist(Y[:, 1], bins=500, alpha=0.7, label='Target py')\n",
    "plt.title('MLMET Targets')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(-2,2)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram for puppi_met_pred (PUMET feature array)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(puppi_met_components[:, 0], bins=50, alpha=0.7, label='PUMET px')\n",
    "plt.hist(puppi_met_components[:, 1], bins=50, alpha=0.7, label='PUMET py')\n",
    "plt.title('PUMET Predictions')\n",
    "plt.xlim(-250,250)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# Plot histogram for Y (PUMET target array, same as above)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(Y[:, 0], bins=500, alpha=0.7, label='Target px')\n",
    "plt.hist(Y[:, 1], bins=500, alpha=0.7, label='Target py')\n",
    "plt.title('PUMET Targets')\n",
    "plt.xlabel('Value')\n",
    "plt.xlim(-2,2)\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for MET phi\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(convertXY2PtPhi(Y)[:,1], bins=500, alpha=0.7, label='Target MET Phi')\n",
    "plt.title('MET Phi Targets')\n",
    "plt.xlabel('Phi')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(-3.5,3.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a new model with all layers after layer 13 removed\n",
    "\n",
    "# Get the output of layer 13 (indexing starts from 0)\n",
    "layer_w_out = model.get_layer('met_weight_minus_one').output\n",
    "\n",
    "# Create a new model from the same inputs to the output of layer 13\n",
    "model_w = Model(inputs=model.input, outputs=layer_w_out)\n",
    "\n",
    "# Run inference using the new model\n",
    "predictions_w = model_w.predict([X0, X1, X2, X3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = predictions_w.copy()\n",
    "print(test[:,0].squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4101e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for MET weights\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(predictions_w.flatten(), bins=50, alpha=0.7, label='w_x')\n",
    "#plt.hist(predictions_w[:, 1], bins=50, alpha=0.7, label='w_y')\n",
    "plt.title('MLMET Predictions')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten arrays for plotting\n",
    "weights_flat = predictions_w.flatten()  # Layer 14 weights\n",
    "px_flat = X0[..., 1].flatten()                 # px\n",
    "py_flat = X0[..., 2].flatten()\n",
    "print(weights_flat.shape)\n",
    "print('---')\n",
    "print(px_flat.shape)\n",
    "print(py_flat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "                  # py\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot weights vs px\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(px_flat, weights_flat, alpha=0.3, s=2)\n",
    "plt.xlabel('px')\n",
    "plt.ylabel('Layer 14 weights')\n",
    "plt.title('Layer 14 weights vs px')\n",
    "\n",
    "# Plot weights vs py\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(py_flat, weights_flat, alpha=0.3, s=2)\n",
    "plt.xlabel('py')\n",
    "plt.ylabel('Layer 14 weights')\n",
    "plt.title('Layer 14 weights vs py')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0790f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(100*px_flat, bins=1000, alpha=0.7)\n",
    "plt.title('Histogram of px_flat')\n",
    "plt.xlabel('px')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(-500, 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8333973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set modern plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "# X0 has shape (n_events, n_particles, 4), features: [pt, pt*cos(phi), pt*sin(phi), eta]\n",
    "feature_names = ['Transverse Momentum (pₜ)', 'Momentum X (pₓ = pₜ cos φ)', 'Momentum Y (pᵧ = pₜ sin φ)', 'Pseudorapidity (η)']\n",
    "feature_units = ['GeV', 'GeV', 'GeV', '']\n",
    "colors = [\"#281FAF\", \"#281FAF\", \"#281FAF\", \"#281FAF\"]  # Modern color palette\n",
    "\n",
    "n_features = X0.shape[2]\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axs = axs.flatten()  # Make indexing easier\n",
    "\n",
    "for i in range(n_features):\n",
    "    # Remove zeros and get clean data\n",
    "    data_clean = X0[..., i].flatten()\n",
    "    data_no_zeros = data_clean[data_clean != 0]\n",
    "    \n",
    "    # Create histogram with improved styling\n",
    "    n, bins, patches = axs[i].hist(data_no_zeros, bins=80, alpha=0.8, \n",
    "                                   color=colors[i], edgecolor='white', linewidth=0.5)\n",
    "    \n",
    "    # Add gradient effect to bars\n",
    "    #for j, patch in enumerate(patches):\n",
    "    #    patch.set_facecolor(plt.cm.viridis(j / len(patches)))\n",
    "    \n",
    "    # Styling improvements\n",
    "    axs[i].set_title(f'{feature_names[i]}', fontsize=14, fontweight='bold', pad=15)\n",
    "    axs[i].set_xlabel(f'Value [{feature_units[i]}]' if feature_units[i] else 'Value', \n",
    "                      fontsize=12, fontweight='semibold')\n",
    "    axs[i].set_ylabel('Count', fontsize=12, fontweight='semibold')\n",
    "    axs[i].set_yscale('log')\n",
    "    \n",
    "    # Add statistics text box\n",
    "    stats_text = f'Non-zero entries: {len(data_no_zeros):,}\\n'\n",
    "    stats_text += f'Mean: {np.mean(data_no_zeros):.2f}\\n'\n",
    "    stats_text += f'Std: {np.std(data_no_zeros):.2f}'\n",
    "    \n",
    "    axs[i].text(0.98, 0.97, stats_text, transform=axs[i].transAxes, \n",
    "                fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    \n",
    "    # Improve grid\n",
    "    axs[i].grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    axs[i].set_axisbelow(True)\n",
    "    \n",
    "    # Add subtle border\n",
    "    for spine in axs[i].spines.values():\n",
    "        spine.set_edgecolor('gray')\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "# Overall title and layout\n",
    "fig.suptitle('TTbar Feature Distributions (All Cands)', \n",
    "             fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "# Add subtitle with dataset info\n",
    "fig.text(0.5, 0.94, f'Total events: {X0.shape[0]:,} | Particles per event: {X0.shape[1]} | Zero-padded entries excluded', \n",
    "         ha='center', fontsize=11, style='italic', color='gray')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.92])  # Leave space for title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8074068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set modern plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "# Plot PUPPI weights distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# Remove zeros and get clean data for PUPPI weights\n",
    "data_clean = X1[..., 1].flatten()  # PUPPI weights from X1[:, :, 1]\n",
    "data_no_zeros = data_clean[data_clean != 0]\n",
    "\n",
    "# Create histogram with improved styling\n",
    "n, bins, patches = ax.hist(data_no_zeros, bins=80, alpha=0.8, \n",
    "                           color='#281FAF', edgecolor='white', linewidth=0.5)\n",
    "\n",
    "# Styling improvements\n",
    "ax.set_title('PUPPI Weights Distribution', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlabel('PUPPI Weight Value', fontsize=12, fontweight='semibold')\n",
    "ax.set_ylabel('Count', fontsize=12, fontweight='semibold')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Add statistics text box\n",
    "stats_text = f'Non-zero entries: {len(data_no_zeros):,}\\n'\n",
    "stats_text += f'Mean: {np.mean(data_no_zeros):.2f}\\n'\n",
    "stats_text += f'Std: {np.std(data_no_zeros):.2f}'\n",
    "\n",
    "ax.text(0.98, 0.97, stats_text, transform=ax.transAxes, \n",
    "        fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "\n",
    "# Improve grid\n",
    "ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Add subtle border\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor('gray')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.88])  # Leave space for subtitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d5343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l1metml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
