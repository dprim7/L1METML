callbacks:
  learning_rate:
    type: cosine_decay #currently doesn't work other than setting learning rate
    initial_learning_rate: 0.01
    decay_steps: 100000
    alpha: 0.0
  cyclical_lr:
    base_lr: 0.003
    max_lr: 0.001
    mode: triangular2
  early_stopping:
    monitor: val_loss
    patience: 40
  reduce_lr_on_plateau:
    reduce: true
pruning:
  prune: false 
  pruning_schedule: polynomial
  target_sparsity: 0.40
  begin_step: 2000
  end_step: 100000
  frequency: 100
data:
  compute_edge_feat: 0
  edge_features: []
  maxNPF: 128
  n_features_pf: 7
  n_features_pf_cat: 2
  normFac: 100
  preprocessed: true
loss:
  symmetry_weight: 1.0
  use_symmetry: false
  mse_weight: 1.0
  baseline_loss: true
  mae_weight: 2.0
  add_respcorr: true
  respcorr_factor: 4.0
model:
  activation: tanh
  emb_out_dim: 8
  type: dense_embedding
  units:
  - 32
  - 16
  with_bias: false
optimizer:
  clipnorm: 1.0
  learning_rate: 1.0
  type: adam
quantization:
  enabled: false
  int_bits: 2
  total_bits: 7
training:
  batch_size: 512
  epochs: 250
  mode: 1
  normFac: 100
  workflow_type: dataGenerator
